\documentclass[10pt, a4paper]{article}
\usepackage{multicol}
\usepackage{amsfonts, amsmath, amssymb, amsthm}
\usepackage[none]{hyphenat}
\usepackage{CJKutf8}
\usepackage[T1]{fontenc} % Latin Extended font
\usepackage{ebgaramond} % EB Garamond font
\usepackage{tgheros}    % TeX Gyre Heros font
\usepackage[strict,autostyle]{csquotes} % smart and nestable quote marks
\usepackage[USenglish]{babel} % American English
\usepackage{microtype}% improve text appearance with kerning, etc
\usepackage{datetime} % formatting of date 
\usepackage{tabto}    % make nice tabbing
\usepackage{hyperref} % enable hyperlinks and pdf metadata
\usepackage[top=2cm, bottom=2cm, left=2.5cm, right=2cm]{geometry} % manually set page margins
\usepackage{enumitem} % enumerate with [resume] option
\usepackage{titlesec} % allow custom section fonts
\usepackage{setspace} % custom line spacing
\usepackage{graphicx}
\usepackage{cuted}
\usepackage{caption}

\title{On the Mean Accuracy of Statistical Pattern Recognizers}
\author{GORDON P. HUGHES, MEMBER, IEEE }
\date{JAN 1968}

\begin{document}
\begin{CJK*}{UTF8}{bsmi}

\maketitle

\setlength{\columnsep}{0.5cm}
\begin{multicols}{2}

\section*{Abstract}
\hspace*{1em} The overall mean recognition probability (mean accuracy) of a pattern classifier is calculated and numerically plotted as a function of the pattern measurement complexity $\mathbb{R}$ and design data set size $m$. 
Utilized is the well-known probabilistic model of a two-class, discrete-measurement pattern environment (no Gaussian or statistical independence assumptions are made). 
The minimum error recognition rule (Bayes) is used, with the unknown pattern environment probabilities estimated from the data relative frequencies. 
In calculating the mean accuracy over all such environments, only three parameters remain in the final equation: $n$, $m$, and the prior probability $p_c$ of either of the pattern classes.\\ 
\hspace*{1em} With a fixed design pattern sample, recognition accuracy can first increase as the number of measurements made on a pattern increases, but decay with measurement complexity higher than some optimum value. 
Graphs of the mean accuracy exhibit both an optimal and a maximum acceptable value of $n$ for fixed $m$ and $p_c$. A four-place tabulation of the optimum $n$ and maximum mean accuracy values is given for equally likely classes and $m$ ranging from 2 to 1000.\\
\hspace*{1em} The penalty exacted for the generality of the analysis is the use of the mean accuracy itself as a recognizer optimal criterion. 
Namely, one necessarily always has some particular recognition problem at hand whose Bayes accuracy will be higher or lower than the mean over all recognition problems having fixed $n$, $m$, and $p_c$. 

\section{Introduction}
\hspace*{1em} Some consequences of the statistical model of pattern recognition will be presented.
It will be shown that certain useful numerical conclusions can be drawn from rather few assumptions. 
Basically, the only assumption made is that some unknown discrete probability structure underlies the pattern environment. 
This structure defines the particular recognition problem under consideration.
A pattern is obtained by making a sample measurement on the environment. 
Each possible pattern is to be classified into one of a set of classes by a \textit{recognition rule} having maximal probability of correct classification (Figure 1). \\
\begin{center}
    \includegraphics[width=0.25\textwidth]{Known_probability_example.PNG}
    \captionof{figure}{Know Probability Example}
    \label{fig:Know_Probability_Example}
\end{center}
\hspace*{1em} It is hoped that this model is sufficiently simple and standard to be readily accepted. 
The intent of the present analysis is to obtain results which follow from the statistical model itself; e.g., without constraining the unknown probabilities to be Gaussian or otherwise parametric. 
For the same reason, no assumption of statistical independence between pattern measurements will be made. 
However, only the case of two pattern classes will be treated. \\
\hspace*{1em} An optimality criterion will be proposed for recognition rules designed from data sets of $m$ sample patterns. 
The measurement complexity $n$ (total number of discrete values) will also be used as a parameter. 
It will be shown that it is also desirable to exhibit explicitly the prior probability $p_{c1}$ of class $c_1$ as the third criterion parameter (where $p_{c2} = 1 - p_{cl}$). \\
\hspace*{1em}The criterion proposed is the mean correct recognition probability $p_{cr}(n, m, p_{c1})$ over all pattern environments. 
It is obtained by first fixing $n$, $m$, and $p_{c1}$ and calculating the accuracy $P_{cr}(n, m, p_{c1})$ of the minimal error-rate Bayes recognition rule for any given environment probability structure. 
This accuracy is then averaged over all such probability structures, giving the mean accuracy $P_{cr}(n, m, p_{c1})$. 
The resultant equation will be numerically evaluated for practical ranges of $n$, $m$, and $p_{c1}$. 
Some interesting optimality relationships will thereby be exhibited.\\
\hspace{1em} A forewarning should be made of a potential misinterpretation of this criterion. 
In the literature, the term “mean Bayes accuracy” often refers to averaging only over the possible measurement values of a fixed recognition problem, namely, one having some known environment probability structure. 
Here, the mean refers to averaging over all recognition problems having fixed measurement complexity $n$ and prior class probability $p_{c1}$. 
For example, this includes all subsets of parametric and/or statistically dependent probability structures, as well as all other discrete, normalizable structures. 
Consequently, the criterion evaluates the overall performance of a Bayes recognition rule. 
Middleton(Section 23.4) presents a useful background discussion on criteria selection.\\

\section{Statistical Model}
\hspace{1em} A statement of the statistical pattern recognition model to be used will first be made. It is fairly standard and contains as few assumptions and constraints as possible. 
By the term "model" is meant that all the required assumptions are stated, and the applicability of the subsequent analysis to particular recognition problems can be judged on the model itself. \\
\hspace{1em} It is assumed that there exist two statistical environments called (caused by) pattern classes $c_l$ and $c_2$. 
Each environment is characterized by a constant but unknown probability distribution over the $n$ discrete values of the pattern measurement variable $x$. 
Namely, $P(x_i | c_1)$ is the probability of measurement value $X_i$ occurring in environment $c_1$ for $i = 1, 2, . . . , n$. These scalars are termed the cell probabilities. Similarity, the unknown distribution $P(x_i | c_2)$ characterizes $X$ under the second environment $c_2$. Vector measurements will be discussed later. \\
\hspace{1em} By unlcnown, it is meant that no prior information whatever is given on the $2n$ scalars $P(x_i | c_i)$. Any pair of distributions is equally likely a priori. Sample pattern data from the environments is to be measured to estimate the actual $P(x_i | c_i)$ existing in any specific recognition problem (the sample relative frequencies will be used). \\
\hspace{1em} Thus, the only constraints are that all probabilities be non-negative and that 
\begin{equation}
    \sum_{i=1}^{n}P(x_i | c_1) = \sum_{i=1}^{n}P(x_i | c_2) = 1
\end{equation}
\hspace{1em} Whenever a measurement $x$ is made, there is a known prior class probability $p_{c1}$, that class $c_1$ is in effect and $P(x_i | c_i)$ applies. 
With the complementary probability $p_{c2} = 1 - p_{c1}$, class $c_2$ and $P(x_i | c_2)$ are in effect. 
However, the particular class in effect for any pattern is not known: only the value $x_i$ produced by the pattern measurement is available. \\
\hspace{1em} The pattern recognition problem is to design a recognition rule to predict (recognize) the pattern class most likely in effect for each of the $n$ possible measurement values $x_i$. 
Its theoretic solution is known to be a maximal class recognition accuracy Bayes rule.
Specifically, this rule is to predict $c_1$ when $x_i$ occurs if $P(c_1 | x_i) > P(c_2 | x_i)$; otherwise predict $c_2$.
This superficially simple rule states to choose the more probable class, given the measurement value $x_i$ which has occurred. The resultant correct recognition probability (accuracy) is then
\begin{align}
    P_{cr}(n, p_{c1}) &= \sum_{i=1}^{n}\left[ \underset{j=1,2}{\max} P(c_j | x_i)\right]P(x_i)\\
    &=\sum_{i=1}^{}\underset{j}{\max} P(c_j | x_i)\\
    &=\sum_{i=1}^{}\left[\underset{j}{\max} P(x_i | c_j)p_{cj}\right]
\end{align}
\hspace{1em} Note that no assumption of measurement statistical independence is made (Appendix I). 
Also, a vector of $r$ discrete measurements, each having $n_k$ values, $k = 1, 2, ... r$, is clearly equivalent to a single measurement with 
\begin{equation}
    n=n_1 n_2 ... n_r
\end{equation}
Appendix I details this equivalence.\\
\hspace{1em} Use of discrete measurement values in the model is dictated by practical considerations. 
Namely, measurements can be made only to a finite precision and consequently only a finite number $n$ of different values can result. 
Thus $n$ can be termed the measurement complexity. 
Many recognition problems are explicitly digital, such as the visual patterns usually arising in character recognition.\\

\section{Infinite Data Sets}
\hspace{1em} Although the unknown probabilities $P(x_i | c_j)$ must actually be statistically estimated from finite pattern sets, the limiting case of known probabilities $(m = \infty)$ will be first developed. 
For example, the two histograms of Figure 1 give $P(x_i | c1)$ and $P(x_i | c_2)$ for a problem having $n = 5$. 
Given that the classes are equally likely $(p_{c1} = p_{c2} = \frac{1}{2})$, the optimal recognition rule for the five values is as shown, and the recognition accuracy from (3) and (4) is
\begin{align}
    P_{cr}(5, \frac{1}{2})=P(c_2|x_1)+P(c_2|x_2)+P(c_2|x_3) \notag \\
    +P(c_1|x_4)+P(c_1|x_5)=0.65
\end{align}
\hspace{1em} It is obvious, but still important to note, that this Bayes accuracy of 65 percent is the best possible for the probability structure of Figure 1. 
No amount of “improved recognizer design” can increase this figure. 
Clearly all accuracy will lie between max $(p_{c1}, 1 -p_{c1})$ and unity, since the former can be obtained with no measurements whatever (the rule would be always to predict the same class, that having higher prior probability). 
In fact, it will be shown in (16) that the highest average accuracy $(n = \infty)$ is only 75 percent for $p_{c1} = \frac{1}{2}$. \\
\hspace{1em} Next, it may be observed that the distributions of Figure 1 possess no particular continuity, symmetry, or modality over the $x_i$ range. 
No reasonable parametric forms could be assumed for $P(x_i|c_1)$ and $P(x_i|c_2)$, such as a pair of Gaussian density functions
\begin{align}
    P(x_i|c_j) &= N(\mu_i, \sigma_j) \notag \\
    &= \left(1/\sqrt{2\pi\mu^2_j}\right)\ \exp\ \left[-(x_i-\mu_j)^2/2\mu^2_j\right] \notag
\end{align}
\hspace{1em} This non-parametric aspect of the pattern environment appears to be common to many recognition problems. 
It is further discussed in Section VII, using some sample histograms from photographic recognition data.
\hspace{1em} Alternative parametric assumptions have been tried by several workers. 
These include heuristic fitting of an overlapping sequence of multivariate Gaussian densities to the data.
Local smoothness assumptions have been made on the densities, according to a metric which leads to a nearest neighbor recognition rule.
However, the continuity constraints which would be imposed on the model by these assumptions are of an entirely different nature than the simple normalizing constraints of (1). Also, the validity of such assumptions is often difficult to verify (see Kendall and Stuart, Section 30.63). \\
\hspace{1em} In keeping with the desire for minimal constraints on the model, no such continuity or parametric requirements will be imposed at all. 
Instead, sample pattern data will be used to estimate individually the discrete cell probabilities by computing relative frequencies. \\

\section{Evaluation Criterion}
\hspace{1em} A natural criterion to evaluate recognition rule performance is the expected or mean Bayes recognition accuracy over all possible environment probabilities $P(x_i|c_j)$. 
Namely, no prior information on each scalar $P(x_i|c_j)$ is to be assumed before the sample pattern data are measured. 
Any set of $2n$ positive real probability values is equally likely as long as (1) is satisfied.\\
\hspace{1em} Clearly, if any such set were made more likely than another, then the criterion would emphasize the accuracy on that particular recognition problem. 
Instead, the criterion is to weigh equally all recognition problems having given values of $p_{c1}$ and $n$. \\
\hspace{1em} It should be remarked that $p_{c1}$ is explicitly exhibited as a parameter because recognition rule performance should be judged against the minimum accuracy of max $(p_{c1}, 1-p_{c1})$ using no measurements. If $p_{c1}$ lies near zero or unity, then any recognizer should have nearly 100 percent accuracy. \\
\hspace{1em} Thus the Bayes accuracy of (4) is a statistic, in that it is a function of the random variables
\begin{align}
    \mu_i &\simeq P(x_i|c_1) \notag \\
    \nu_i &\simeq P(x_i|c_2) \qquad  i=1,2,...,n 
\end{align}
\hspace{1em} To compute its mean or expected value, first note that the $\mu_i$ and $\nu_i$ are uniformly distributed due to the “equally likely” assumption of the model: 
\begin{align}
    &dP(\mu_1, \mu_2,..., \mu_n, \nu_1, \nu_2,...,\nu_n) \notag \\
    &= N\ d\mu_1\ d\mu_2\ ... d\mu_{n-1}\ d\nu_1\ d\nu_2\ ...\ d\nu_{n-1}
\end{align}
\hspace{1em} Only $2(n - 1)$ differentials appear on the right of (8) because the two normalizing equations (1) fix $\mu_n$ and $\nu_n$, in terms of the others. 
Now, the boundaries of the $(n - l)$order distribution of the $\mu_i$ alone are given by the intersection of the hypercube $0 \leq \mu_i \leq 1, i = 1, 2, . . . , n - 1$, and the symmetric hyperplane 
\begin{align}
    \sum_{i=1}^{n-1}\mu_i = 1
\end{align}
which is also caused by (1). 
An identical boundary structure holds for the $\nu_i$, so that the normalizing constant $N$ in (8) is obtained from 
\begin{align}
    1=N \left[ \int_0^1 d\mu_1 \int_0^{1-\mu_1} d\mu_2 \int_0^{1-\mu_1-\mu_2} d\mu_3 \dots \right. \notag \\
    \quad \left. \int_0^{1-\mu_1-\mu_2...-\mu_{n-2}} d\mu_{n-1} \right] \notag \\
    \left[ \int_0^1 d\nu_1 \int_0^{1-\nu_1} d\nu_2 \int_0^{1-\nu_1-\nu_2} d\nu_3 \dots \right. \notag \\
    \quad \left. \int_0^{1-\nu_1-\nu_2...-\nu_{n-2}} d\nu_{n-1} \right] 
\end{align}
\hspace{1em} These two iterated integrals may be easily evaluated, giving 
\begin{align}
    N=[(n-1)!]^2
\end{align}
\hspace{1em} Equation (4) is the recognition accuracy given the $\mu_i$, $\nu_i$ and is multiplied by (8) to obtain a joint probability. 
This is integrated over the $\mu_i$, $\nu_i$ range to get the mean accuracy. 
By symmetry, each of the $n$ terms of (4) will have an identical expected value, so that $n$ times the expected value of the first may be taken: 



\end{multicols}
\end{CJK*}
\end{document}
